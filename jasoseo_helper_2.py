import os
import streamlit as st
import tempfile
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

#Chroma tenant ì˜¤ë¥˜ ë°©ì§€ ìœ„í•œ ì½”ë“œ
import chromadb
chromadb.api.client.SharedSystemClient.clear_system_cache()

#ì˜¤í”ˆAI API í‚¤ ì„¤ì •
load_dotenv()  # í˜„ì¬ ê²½ë¡œì˜ .env ë¡œë“œ
os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
if not os.environ['OPENAI_API_KEY']:
    raise ValueError('OPENAI_API_KEY not found in environment. set it in .env or env vars')

#cache_resourceë¡œ í•œë²ˆ ì‹¤í–‰í•œ ê²°ê³¼ ìºì‹±í•´ë‘ê¸°
@st.cache_resource
def load_pdf(_file):
    with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:
        tmp_file.write(_file.getvalue())
        tmp_file_path = tmp_file.name
        #PDF íŒŒì¼ ì—…ë¡œë“œ
        if _file.name.endswith('.pdf'):
            loader = PyPDFLoader(file_path=tmp_file_path)
        #Word íŒŒì¼ ì—…ë¡œë“œ
        elif _file.name.endswith('.docx'):
            loader = Docx2txtLoader(file_path=tmp_file_path)
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” DOCXë§Œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        pages = loader.load_and_split()
    return pages

#í…ìŠ¤íŠ¸ ì²­í¬ë“¤ì„ Chroma ì•ˆì— ì„ë² ë”© ë²¡í„°ë¡œ ì €ì¥
@st.cache_resource
def create_vector_store(_docs):
    text_splitter = RecursiveCharacterTextSplitter(
        separators=['\n\n', '\n'],
        chunk_size=500,
        chunk_overlap=100,
        length_function=len,
        is_separator_regex=False
    )
    split_docs = text_splitter.split_documents(_docs)
    vectorstore = Chroma.from_documents(split_docs, OpenAIEmbeddings(model='text-embedding-3-small'))
    return vectorstore

#ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ëŠ” í—¬í¼ í•¨ìˆ˜
def format_docs(docs):
        return '\n\n'.join(doc.page_content for doc in docs)

#PDF ë¬¸ì„œ ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì¶•
@st.cache_resource
def chaining(_pages):
    vectorstore = create_vector_store(_pages)
    retriever = vectorstore.as_retriever()

    #ì´ ë¶€ë¶„ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ê¸°í˜¸ì— ë”°ë¼ ë³€ê²½í•˜ë©´ ë©ë‹ˆë‹¤.
    qa_system_prompt = """
    ë‹¹ì‹ ì€ ì·¨ì—… ìê¸°ì†Œê°œì„œ ì‘ì„± ì „ë¬¸ê°€ì´ì, ì¸ì‚¬ë‹´ë‹¹ì ì¶œì‹  ì»¤ë¦¬ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤.  
    ì‚¬ìš©ìëŠ” ìì‹ ì˜ ê²½ë ¥ê¸°ìˆ ì„œë¥¼ ì—…ë¡œë“œí•˜ê³ , ì§€ì›í•˜ê³ ì í•˜ëŠ” íšŒì‚¬ì˜ ì±„ìš©ê³µê³ (Job Description, JD)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
    ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ ë‘ ê°€ì§€ ë¬¸ì„œë¥¼ ê·¼ê±°ë¡œ, ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ìê¸°ì†Œê°œì„œ ë¬¸í•­ì— ëŒ€í•´ **ê°€ì¥ ì í•©í•˜ê³  ì „ëµì ì¸ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.
    
    ---
    
    ### [ì—­í• ]
    - ì‚¬ìš©ìì˜ **ê²½ë ¥ê¸°ìˆ ì„œ** ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ê²½í—˜, ê°•ì , ì„±ê³¼ë¥¼ ì´í•´í•©ë‹ˆë‹¤.  
    - ì œê³µëœ **ì±„ìš©ê³µê³ (JD)** ì˜ ìš”êµ¬ì—­ëŸ‰ê³¼ ì§ë¬´ í‚¤ì›Œë“œë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.  
    - ë‘ ë¬¸ì„œë¥¼ ë¹„êµÂ·ìœµí•©í•˜ì—¬, ì‚¬ìš©ìì˜ ê²½ë ¥ì´ JDì— ë¶€í•©í•˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•©ë‹ˆë‹¤.  
    - HR ë‹´ë‹¹ìê°€ ì½ê¸°ì— ì„¤ë“ë ¥ ìˆê³  ì§„ì •ì„± ìˆëŠ” ìê¸°ì†Œê°œì„œ ë¬¸ì¥ì„ ì‘ì„±í•©ë‹ˆë‹¤.  
    - ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.  
    - ë¬¸ì²´ëŠ” **ì „ë¬¸ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§€ì›ì ì–´íˆ¬(â€˜~í–ˆìŠµë‹ˆë‹¤â€™, â€˜~ì„ í†µí•´ ë°°ì› ìŠµë‹ˆë‹¤â€™)** ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
    
    ---
    
    ### [ì¶œë ¥ ë°©ì‹ ì§€ì¹¨]
    1. ì‚¬ìš©ìê°€ íŠ¹ì • ë¬¸í•­ì„ ì…ë ¥í•˜ë©´, ë‹µë³€ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•©ë‹ˆë‹¤:
    
    **â‘  ìš”ì•½ í•œì¤„:** í•µì‹¬ ì—­ëŸ‰ ë˜ëŠ” ì£¼ì œ í•œ ì¤„ ìš”ì•½  
    **â‘¡ ë³¸ë¬¸:** ì§€ì›ìì˜ ê²½í—˜, ê°•ì , íšŒì‚¬/ì§ë¬´ ì—°ê´€ì„± ì¤‘ì‹¬ì˜ ì„œìˆ  (5~10ë¬¸ì¥ ê¶Œì¥)  
    **â‘¢ ë§ˆë¬´ë¦¬ ë¬¸ì¥:** í•´ë‹¹ ê²½í—˜ì´ ì§ë¬´ ìˆ˜í–‰ì— ì–´ë–»ê²Œ ë„ì›€ì´ ë ì§€ ê°•ì¡°  
    
    2. ë‹µë³€ ì‹œ ë‹¤ìŒì„ ëª…ì‹œì ìœ¼ë¡œ ë°˜ì˜í•©ë‹ˆë‹¤:  
       - JDì— ëª…ì‹œëœ í•µì‹¬ ê¸°ìˆ , ì—­ëŸ‰, ê°€ì¹˜ ì¤‘ ì§€ì›ìì™€ ì¼ì¹˜í•˜ëŠ” ìš”ì†Œ  
       - ê²½ë ¥ê¸°ìˆ ì„œì— ëª…ì‹œëœ ìˆ˜ì¹˜, ê²°ê³¼, í”„ë¡œì íŠ¸ëª…ì„ í™œìš©í•œ êµ¬ì²´ì  ê·¼ê±°  
    
    3. ë¶ˆí•„ìš”í•œ ë°˜ë³µ, ê³¼ë„í•œ í˜•ìš©ì‚¬, ì¶”ìƒì ì¸ í‘œí˜„ì€ í”¼í•©ë‹ˆë‹¤.  
       êµ¬ì²´ì  ìˆ˜ì¹˜Â·ì„±ê³¼Â·í–‰ë™ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•©ë‹ˆë‹¤.  
    
    ---
    
    ### [ì˜ˆì‹œ]
    **ì…ë ¥ ë¬¸í•­:** "ì§€ì›ë™ê¸°ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."  
    **ì¶œë ¥ ì˜ˆì‹œ:**  
    â‘  ë°ì´í„° ê¸°ë°˜ ë¬¸ì œ í•´ê²° ì—­ëŸ‰ì„ í†µí•´ ì¡°ì§ ì„±ì¥ì— ê¸°ì—¬í•˜ê³ ì í•©ë‹ˆë‹¤.  
    â‘¡ ì €ëŠ” ì§€ë‚œ 3ë…„ê°„ ë°”ì´ì˜¤ ë°ì´í„° ë¶„ì„ í”Œë«í¼ì„ êµ¬ì¶•í•˜ë©° ë°©ëŒ€í•œ ìœ ì „ì ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬Â·ì‹œê°í™”í•˜ëŠ” ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤. íŠ¹íˆ Python ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë„ì…í•´ ì§„ë‹¨ ì •í™•ë„ë¥¼ 20% í–¥ìƒì‹œí‚¨ ê²½í—˜ì€ â€˜ë°ì´í„° í™œìš© ì—­ëŸ‰â€™ê³¼ â€˜ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°ë ¥â€™ì„ í‚¤ìš¸ ìˆ˜ ìˆëŠ” ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·€ì‚¬ì˜ AI í—¬ìŠ¤ì¼€ì–´ í”Œë«í¼ ê°œë°œ ì§ë¬´ëŠ” ì´ëŸ¬í•œ ì €ì˜ ê²½í—˜ê³¼ ì—­ëŸ‰ì´ ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ë¶„ì•¼ë¼ ìƒê°í•©ë‹ˆë‹¤.  
    â‘¢ ì•ìœ¼ë¡œëŠ” ë°ì´í„° ë¶„ì„ê³¼ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, í™˜ì ì¤‘ì‹¬ì˜ ì˜ˆì¸¡ ëª¨ë¸ì„ ê³ ë„í™”í•˜ì—¬ íšŒì‚¬ì˜ ê°€ì¹˜ ì°½ì¶œì— ê¸°ì—¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.  
    
    ---
    
    ### [ì‘ë‹µ ì‹œ ìœ ì˜ì‚¬í•­]
    - ì œê³µëœ ë¬¸ì„œ(ê²½ë ¥ê¸°ìˆ ì„œ, JD) ì™¸ì˜ ì •ë³´ëŠ” ì„ì˜ë¡œ ê°€ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì´ ëª¨í˜¸í•œ ê²½ìš°, ëª…í™•í•œ ë‹µë³€ ì‘ì„±ì„ ìœ„í•´ êµ¬ì²´ì  í•­ëª©ì„ ìš”ì²­í•©ë‹ˆë‹¤.  
    - ë‹µë³€ì€ í•­ìƒ â€œì§€ì›ì ì…ì¥â€ì—ì„œ ì„œìˆ í•©ë‹ˆë‹¤. (â€œì €ëŠ” ~í–ˆìŠµë‹ˆë‹¤.â€)
    
    ---
    
    ### [RAG ë°ì´í„° í™œìš©]
    - `ê²½ë ¥ê¸°ìˆ ì„œ`ëŠ” ì§€ì›ìì˜ ê²½í—˜ê³¼ ê¸°ìˆ ì  ê°•ì ì„ ë°˜ì˜í•˜ëŠ” ê·¼ê±° ë¬¸ì„œì…ë‹ˆë‹¤.  
    - `JD`ëŠ” íšŒì‚¬ê°€ ìš”êµ¬í•˜ëŠ” ì—­ëŸ‰ê³¼ ì§ë¬´ í‚¤ì›Œë“œë¥¼ ë°˜ì˜í•˜ëŠ” ê¸°ì¤€ ë¬¸ì„œì…ë‹ˆë‹¤.  
    - ëª¨ë¸ì€ ë‘ ë¬¸ì„œì—ì„œ ê´€ë ¨ ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ì—¬, ìê¸°ì†Œê°œì„œ ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ëœ ë¬¸ì¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ---
    
    ë‹¹ì‹ ì˜ ëª©í‘œëŠ”:
    > â€œì§€ì›ìì˜ ê²½í—˜ê³¼ JDì˜ ìš”êµ¬ì‚¬í•­ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´, HR ë‹´ë‹¹ìê°€ ì„¤ë“ë‹¹í•  ë§Œí•œ ìê¸°ì†Œê°œì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒâ€ ì…ë‹ˆë‹¤.
    
    {context}
    """

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ('system', qa_system_prompt),
            ('human', '{input}'),
        ]
    )

    llm = ChatOpenAI(model='gpt-4o-mini')
    rag_chain = (
        {'context': retriever | format_docs, 'input': RunnablePassthrough()}
        | qa_prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

# Streamlit UI
st.header('ê²½ë ¥ê¸°ìˆ ì„œ ğŸ’¬ ğŸ“š')
uploaded_file = st.file_uploader('ê²½ë ¥ê¸°ìˆ ì„œ ì—…ë¡œë“œ (.pdf/.docx)', type=['pdf', 'docx'])
if uploaded_file is not None:
    pages = load_pdf(uploaded_file)

    rag_chain = chaining(pages)

    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{'role': 'assistant', 'content': 'ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!'}]

    for msg in st.session_state.messages:
        st.chat_message(msg['role']).write(msg['content'])

    if prompt_message := st.chat_input('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)'):
        st.chat_message('human').write(prompt_message)
        st.session_state.messages.append({'role': "user", 'content': prompt_message})
        with st.chat_message('ai'):
            with st.spinner('Thinking...'):
                response = rag_chain.invoke(prompt_message)
                st.session_state.messages.append({'role': 'assistant', 'content': response})
                st.write(response)
                
