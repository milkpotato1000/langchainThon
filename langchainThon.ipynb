{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af3cb2d-a2a3-4678-adb0-aed0935a73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from docx2txt import docx2txt  # optional, but you used Docx2txtLoader previously\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad355284-e0cc-4b90-a93e-90d59d654c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY ë¶ˆëŸ¬ì™€ í™˜ê²½ë³€ìˆ˜ë¡œ ì €ì¥\n",
    "load_dotenv()  # í˜„ì¬ ê²½ë¡œì˜ .env ë¡œë“œ\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "if not os.environ['OPENAI_API_KEY']:\n",
    "    raise ValueError('OPENAI_API_KEY not found in environment. set it in .env or env vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99ffd3e-9b55-445d-af03-5244b965f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client (ì§ì ‘ chat.completions í˜¸ì¶œìš©)\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb14d70-0699-4556-bd0a-e6a73e33d360",
   "metadata": {},
   "source": [
    "## 1. ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° & í…ìŠ¤íŠ¸ ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6885f599-b6b6-411d-88df-2b3709027597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ë¡œë“œ\n",
    "docx_path = \"../data/langchainThon/cv/ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx\"\n",
    "full_text = docx2txt.process(docx_path)  # ì „ì²´ í…ìŠ¤íŠ¸ í•˜ë‚˜ë¡œ ì½í˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79bd8082-bb1c-4ef0-ac4c-2ac21d9d7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ë‚˜ëˆ„ê¸°\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n'],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "chunks = text_splitter.split_text(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00c6df7-a869-4759-b274-ecfbc2fec1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— metadata ì¶”ê°€\n",
    "documents = []\n",
    "for i, c in enumerate(chunks):\n",
    "    metadata = {\n",
    "        \"source\": \"ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx\",\n",
    "        \"chunk_id\": str(i),\n",
    "        # í•„ìš”í•˜ë©´ ë” ë§ì€ ë©”íƒ€ ì¶”ê°€ (ì˜ˆ: section headings, page num)\n",
    "    }\n",
    "    documents.append(Document(page_content=c, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff30dc7f-93bb-4f0f-8245-8e6de760ae48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '0'}, page_content='ê²½ë ¥ê¸°ìˆ ì„œ\\n\\n[ê°œì¸ ì •ë³´]\\n\\nì´ë©”ì¼: fourleaves8@gmail.com\\n\\nì—°ë½ì²˜: 010-4788-7980\\n\\n\\n\\n[ì „ë¬¸ ë¶„ì•¼]\\n\\nâ€¢ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤       \\t\\t â€¢ AI ì—”ì§€ë‹ˆì–´ë§\\t\\n\\nâ€¢ ë°ì´í„° ë¶„ì„           \\t\\t â€¢ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\\n\\nâ€¢ ìƒë¬¼ë¶„ì ë° í™”í•™ê³µí•™ ì—°êµ¬\\n\\n\\n\\n[ìš”ì•½]\\n\\nì €ëŠ” ìƒëª…Â·ì˜í•™ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„ í”Œë«í¼ì„ êµ¬ì¶•í•œ ê²½í—˜ ë° ë³µì¡í•œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì„í•´ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•˜ëŠ” ì—­ëŸ‰ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. Python ê¸°ë°˜ì˜ ë°ì´í„° ì „ì²˜ë¦¬, ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”, ë¶„ë¥˜ ë° ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œì„ í†µí•´ í•­ì•”ì œ ì‹ ê·œ ì ì‘ì¦ íƒìƒ‰ í”Œë«í¼ì„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•œ ë°” ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë°ì´í„° ìˆ˜ì§‘Â·ì •ê·œí™”Â·ì‹œê°í™” ì „ ê³¼ì •ì„ ì£¼ë„í•˜ë©°, ìŠ¤íƒ€íŠ¸ì—…ì˜ ì½”ìŠ¤ë‹¥ ìƒì¥ ë° ì‹¤ì œ ì œì•½ì‚¬ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•œ ì‹¤ë¬´ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤. \\n\\n\\n\\n[ë³´ìœ  ì—­ëŸ‰ ë° ê¸°ìˆ ]\\n\\ní”„ë¡œê·¸ë˜ë° ì–¸ì–´\\n\\nPython, R, SQL, Java\\n\\në„êµ¬ ë° í”„ë ˆì„ì›Œí¬'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '1'}, page_content='[ë³´ìœ  ì—­ëŸ‰ ë° ê¸°ìˆ ]\\n\\ní”„ë¡œê·¸ë˜ë° ì–¸ì–´\\n\\nPython, R, SQL, Java\\n\\në„êµ¬ ë° í”„ë ˆì„ì›Œí¬\\n\\npandas, NumPy, Matplotlib, seaborn, Plotly, scikit-learn, PyTorch, TensorFlow, RAG, LangChain, MySQL, Oracle\\n\\nìš´ì˜ì²´ì œ\\n\\nLinux(Ubuntu), Windows, macOS\\n\\nPalantir Foundry\\n\\nPipeline Builder, Contour, Ontology(Action), Workshop, AIP, Dataset\\n\\nê¸°íƒ€\\n\\nVim / Vi, Git / GitHub, Bioinformatics Tools (Gene Set Enrichment Analysis, Bismark, Metilene, lifelines, survival, survminer, lifelines)\\n\\n\\n\\n[ì£¼ìš” ê²½ë ¥ ë° í”„ë¡œì íŠ¸]'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '2'}, page_content='[ì£¼ìš” ê²½ë ¥ ë° í”„ë¡œì íŠ¸]\\n\\n(ì£¼)ì˜¨ì½”í¬ë¡œìŠ¤ Â· AI ì—°êµ¬ì†Œ Â· ì£¼ì„ì—°êµ¬ì›â€“ì „ì„ì—°êµ¬ì› Â· 2021.01â€“2024.12 (4ë…„ê°„ ê·¼ë¬´)\\n\\n\\n\\n<í”„ë¡œì íŠ¸1 : í•­ì•”ì œ ì‹ ê·œ ì ì‘ì¦ íƒìƒ‰ í”Œë«í¼ ê°œë°œ í”„ë¡œì íŠ¸>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í• : í”Œë«í¼ ì „ì²´ ê¸°ëŠ¥ Pythonìœ¼ë¡œ ì¬ êµ¬í˜„, ë‚´ì¬í™” ë° ì˜¤í¼ë ˆì´ì…˜\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2021.01â€“2024.01 (36ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : í”Œë«í¼ ê°œë°œ/ìš´ì˜ Â· ì „ì‚¬ì²´ ë°ì´í„° ë° ì˜ë£Œ ë©”íƒ€ë°ì´í„° ê´€ë¦¬/ë¶„ì„\\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 70%) :\\n\\ní”Œë«í¼ ì „ì²´ ê¸°ëŠ¥ Python êµ¬í˜„ ë° ë‚´ì¬í™” ì™„ë£Œ\\n\\ní”Œë«í¼ ì˜¤í¼ë ˆì´ì…˜ ì „ë°˜ì— ëŒ€í•œ ìœ ì§€, ë³´ìˆ˜, ê´€ë¦¬ ë° ë¶„ì„ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•¨\\n\\nê³µê³µ ë°ì´í„°ë² ì´ìŠ¤ë¡œë¶€í„° 23ê°œ ì•”ì¢…ì— ê±¸ì³ ì•½ 24,000ê°œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ëŒ€ê·œëª¨ ë¶„ì„ ê¸°ë°˜ì„ êµ¬ì¶•í•¨\\n\\nìˆ˜ì§‘í•œ ìƒ˜í”Œ ì „ì‚¬ì²´ ë°ì´í„° ì •ê·œí™” ë° ì •ëŸ‰ì  ìœ ì „ì ë°œí˜„ëŸ‰ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•¨\\n\\ní”Œë«í¼ ëŒ€í‘œ ì„±ê³µ ì‚¬ë¡€'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '3'}, page_content='ìˆ˜ì§‘í•œ ìƒ˜í”Œ ì „ì‚¬ì²´ ë°ì´í„° ì •ê·œí™” ë° ì •ëŸ‰ì  ìœ ì „ì ë°œí˜„ëŸ‰ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•¨\\n\\ní”Œë«í¼ ëŒ€í‘œ ì„±ê³µ ì‚¬ë¡€\\n\\nì¤‘êµ­ ã…‡ã…‡ã…‡ì‚¬ ê°œë°œ ì‹ ê·œ í•­ì•”ì œì˜ ì£¼ ì ì‘ì¦ ì˜ˆì¸¡ ì„±ê³µ ë° ì ì¬ ì ì‘ì¦ í›„ë³´ ì¶”ê°€ ì œì•ˆ\\n\\nêµ­ë‚´ ìœ ëª… ì œì•½ì‚¬ì™€ í˜‘ì—… â€“ í›„ë³´ë¬¼ì§ˆ ê°œë°œ ë‹¨ê³„ ì°¸ì—¬, ê°œë°œ ë¬¼ì§ˆì— ëŒ€í•œ ì ì‘ì¦ í›„ë³´ ë„ì¶œ, ìµœì¢… ì•½ë¬¼ íƒ€ê¹ƒìœ¼ë¡œ ì„ ì •ë˜ì–´ ê°œë°œ ì§€ì†\\n\\nìƒì¥ ê¸°ìˆ í‰ê°€ í•­ëª© 3ê°€ì§€ í”Œë«í¼ ì¤‘ í•˜ë‚˜ë¡œì„œ íšŒì‚¬ ìƒì¥ì— ê¸°ì—¬\\n\\nPython Â· R Â· pandas Â· NumPy Â· scikit-learn Â· Bioinformatics tools (survival, survminer, lifelines, GSEA, etc.) Â· Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<í”„ë¡œì íŠ¸2 : í•­ì•”ì œ í”Œë«í¼ ê³ ë„í™” í”„ë¡œì íŠ¸>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : ì•”ì¢… ë³„, ìœ ì „ì ì˜ˆí›„ ì˜ˆì¸¡ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '4'}, page_content='<í”„ë¡œì íŠ¸2 : í•­ì•”ì œ í”Œë«í¼ ê³ ë„í™” í”„ë¡œì íŠ¸>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : ì•”ì¢… ë³„, ìœ ì „ì ì˜ˆí›„ ì˜ˆì¸¡ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2024.01â€“2024.06 (6ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : 23ê°œ ì•”ì¢…ì— ëŒ€í•œ ìœ ì „ì ë³„ ì˜ˆí›„ ì ìˆ˜ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ì†ë„ 2ë°° (100%) ì´ìƒ ê°œì„ \\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 100%) : \\n\\nì½”ì–´ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ì „ë©´ ìˆ˜ì •\\n\\nì•Œê³ ë¦¬ì¦˜ ìŠ¤ì½”ì–´ë§ ì†ë„ 1100% í–¥ìƒ\\n\\nì•Œê³ ë¦¬ì¦˜ ê°œì„  í›„ ì†Œìš”ì‹œê°„: ìµœëŒ€ 1ì£¼ì¼ (ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜: ìµœì†Œ 3ê°œì›”)\\n\\nPython Â· pandas Â· NumPy Â· scikit-learn Â· Bioinformatics tools (lifelines, GSEA, etc.) Â· Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<í”„ë¡œì íŠ¸3 : ì—‘ì²´ìƒê²€ì„ í†µí•œ ì•” ì¡°ê¸° ì§„ë‹¨ ëª¨ë¸ ê°œë°œ>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  :'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '5'}, page_content='<í”„ë¡œì íŠ¸3 : ì—‘ì²´ìƒê²€ì„ í†µí•œ ì•” ì¡°ê¸° ì§„ë‹¨ ëª¨ë¸ ê°œë°œ>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : \\n\\ncfDNA, ctDNA ë°ì´í„° ìˆ˜ì§‘, ê´€ë¦¬, ë¶„ì„ \\n\\në©”íƒ€ë°ì´í„° ê´€ë¦¬ \\n\\nì•” ì§„ë‹¨ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2025.05â€“2025.11 (6ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : í˜ˆì•¡ cfDNA, ctDNA ë°ì´í„° ìˆ˜ì§‘ ë° í™œìš©, ì•” ì—¬ë¶€ ì˜ˆì¸¡ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ\\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 20%) : \\n\\nëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ (3000ìƒ˜í”Œ ì´ìƒ)\\n\\nì•” ì§„ë‹¨ CNNëª¨ë¸ ê°œë°œ (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '6'}, page_content='ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ (3000ìƒ˜í”Œ ì´ìƒ)\\n\\nì•” ì§„ë‹¨ CNNëª¨ë¸ ê°œë°œ (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)\\n\\nPython Â· pandas Â· NumPy Â· PyTorch, TensorFlow Â· scikit-learn Â· Bioinformatics tools (GSEA, Bismark, Metilene) Â· Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<í”„ë¡œì íŠ¸4 : ì‹ ê·œ COVID-19 ì¹˜ë£Œ í›„ë³´ ì•½ë¬¼ íƒìƒ‰ ë° ì—°êµ¬ ê²°ê³¼ ë…¼ë¬¸ ê²Œì¬>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : Dry-lab ì—°êµ¬, ë‚´ìš© ì •ë¦¬ ë° ë…¼ë¬¸ ì‘ì„±\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2024.01â€“present (21ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : ê³µë™ 1ì €ì(ì£¼ ì €ì), ë…¼ë¬¸ Submission (2024.05.09)\\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 40%) :'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '7'}, page_content='ëª©í‘œ ë° ì—­í•  : ê³µë™ 1ì €ì(ì£¼ ì €ì), ë…¼ë¬¸ Submission (2024.05.09)\\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 40%) : \\n\\nì‚¬ë‚´ í”Œë«í¼ í™œìš© COVID-19 ì¹˜ë£Œ ìœ ë ¥ í›„ë³´ë¬¼ì§ˆ ë°œêµ´ ì„±ê³µ\\n\\nì—°êµ¬ ê²°ê³¼ Scientific reports ì €ë„ì— ì œì¶œ\\n\\n2025ë…„ 9ì›” í˜„ì¬ê¹Œì§€ revision ì§„í–‰ì¤‘ (in press)\\n\\nPython Â· pandas Â· NumPy Â· scikit-learn Â· GSEA Â· Visualization packages (Matplotlib, seaborn)\\n\\n\\n\\n[ìê²©ì¦]\\n\\nOPIc(ì˜ì–´) Â· AL (Advanced Low) Â· 2024.09.20\\n\\në°ì´í„° ë¶„ì„ ì¤€ì „ë¬¸ê°€ (ADsP) Â· 2025.09.05\\n\\n\\n\\n[êµìœ¡ ìˆ˜ë£Œ]\\n\\nGoogle Advanced Data Analytics â€“ Foundations of Data Science\\n\\nGoogle Advanced Data Analytics â€“ Get Started with Python'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '8'}, page_content='Google Advanced Data Analytics â€“ Get Started with Python\\n\\nGoogle Advanced Data Analytics â€“ Go Beyond the Numbers: Translate Data into Insights\\n\\nGoogle Advanced Data Analytics â€“ The Power of Statistics\\n\\nGoogle Advanced Data Analytics â€“ Regression Analysis: Simplify Complex Data Relationships\\n\\nGoogle Advanced Data Analytics â€“ The Nuts and Bolts of Machine Learning\\n\\nPalantir Foundry â€“ Speedrun: Your First End-to-End Workflow\\n\\nPalantir Foundry â€“ Speedrun: Your First AIP workflow'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '9'}, page_content='Palantir Foundry â€“ Speedrun: Your First AIP workflow\\n\\nPalantir Foundry â€“ Deep Dive: Building Your First Pipeline\\n\\nPalantir Foundry â€“ Deep Dive: Creating Your First Ontology\\n\\nPalantir Foundry â€“ Deep Dive: Transforming Your Data with Code Repositories\\n\\nPalantir Foundry â€“ Deep Dive: Building Your First Application\\n\\nPalantir Foundry â€“ Deep Dive: Data Analysis in Contour\\n\\nëª¨ë‘ì˜ ì—°êµ¬ì†Œ â€“ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ê³¼ì • Bootcamp (2025.06~í˜„ì¬ ì§„í–‰ì¤‘)\\n\\n\\n\\n[í•™ë ¥]\\n\\ní•™ìœ„\\n\\nì „ê³µ\\n\\ní•™êµ\\n\\nê¸°ê°„\\n\\në°•ì‚¬ (ìˆ˜ë£Œ)\\n\\nìƒëª…í™”í•™ê³µí•™\\n\\ní•œêµ­ê³¼í•™ê¸°ìˆ ì› (KAIST, ëŒ€ì „)'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '10'}, page_content='[í•™ë ¥]\\n\\ní•™ìœ„\\n\\nì „ê³µ\\n\\ní•™êµ\\n\\nê¸°ê°„\\n\\në°•ì‚¬ (ìˆ˜ë£Œ)\\n\\nìƒëª…í™”í•™ê³µí•™\\n\\ní•œêµ­ê³¼í•™ê¸°ìˆ ì› (KAIST, ëŒ€ì „)\\n\\n2015.08 â€“ 2020.09\\n\\nì„ì‚¬ (ì¡¸ì—…)\\n\\nìƒëª…í™”í•™ê³µí•™\\n\\ní•œêµ­ê³¼í•™ê¸°ìˆ ì› (KAIST, ëŒ€ì „)\\n\\n2015.08 â€“ 2020.09\\n\\ní•™ì‚¬ (ì¡¸ì—…)\\n\\nìƒëª…ê³¼í•™\\n\\nVirginia Tech (ë¯¸êµ­)\\n\\n2011.08\\n\\n\\n\\n[ê¸°íƒ€]\\n\\nGithub Personal Project Repository\\n\\n(https://github.com/milkpotato1000/modulabs_projects)\\n\\nData Science & AIí•™ìŠµ ë¸”ë¡œê·¸ \\n\\n(https://velog.io/@milkpotato1000/posts)\\n\\n\\n\\n\\n\\n     2')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e03f9c-6738-40bf-8394-4d9896379b8c",
   "metadata": {},
   "source": [
    "## 2. ì„ë² ë”© ìƒì„± ë° ë²¡í„° DB ìƒì„± (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8216d644-955c-4b23-a62b-4ae1a45267d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (persist_directory ì§€ì •í•˜ë©´ ì¬ì‚¬ìš© ê°€ëŠ¥)\n",
    "persist_dir = './chroma_resume_db'\n",
    "if not os.path.exists(persist_dir):\n",
    "    os.makedirs(persist_dir, exist_ok=True)\n",
    "\n",
    "# Chroma.from_documents ì„ ì“°ë©´ ë‚´ë¶€ì—ì„œ ì„ë² ë”© ìƒì„± í›„ ì €ì¥\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name='resume_seungwoo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892ff3d-0588-4085-ac2d-1d37669a4b43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Retriever êµ¬ì„± (ê²€ìƒ‰ ì˜µì…˜: simple similarity or MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06a4aa80-ccdb-43da-af34-d25f347c16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as_retrieverë¡œ ê²€ìƒ‰ ë°©ì‹ ë°”ê¿€ ìˆ˜ ìˆìŒ\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',  # mmrë¡œ ë‹¤ì–‘ì„± ìˆëŠ” ê²°ê³¼ (ë‹¤ë¥¸ ì˜µì…˜: \"similarity\")\n",
    "    search_kwargs={'k': 4, 'fetch_k': 10, 'lambda_mult': 0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "446837a5-52a6-413b-bbe7-a6e87c874635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'chunk_id': '3', 'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx'}, page_content='ìˆ˜ì§‘í•œ ìƒ˜í”Œ ì „ì‚¬ì²´ ë°ì´í„° ì •ê·œí™” ë° ì •ëŸ‰ì  ìœ ì „ì ë°œí˜„ëŸ‰ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•¨\\n\\ní”Œë«í¼ ëŒ€í‘œ ì„±ê³µ ì‚¬ë¡€\\n\\nì¤‘êµ­ ã…‡ã…‡ã…‡ì‚¬ ê°œë°œ ì‹ ê·œ í•­ì•”ì œì˜ ì£¼ ì ì‘ì¦ ì˜ˆì¸¡ ì„±ê³µ ë° ì ì¬ ì ì‘ì¦ í›„ë³´ ì¶”ê°€ ì œì•ˆ\\n\\nêµ­ë‚´ ìœ ëª… ì œì•½ì‚¬ì™€ í˜‘ì—… â€“ í›„ë³´ë¬¼ì§ˆ ê°œë°œ ë‹¨ê³„ ì°¸ì—¬, ê°œë°œ ë¬¼ì§ˆì— ëŒ€í•œ ì ì‘ì¦ í›„ë³´ ë„ì¶œ, ìµœì¢… ì•½ë¬¼ íƒ€ê¹ƒìœ¼ë¡œ ì„ ì •ë˜ì–´ ê°œë°œ ì§€ì†\\n\\nìƒì¥ ê¸°ìˆ í‰ê°€ í•­ëª© 3ê°€ì§€ í”Œë«í¼ ì¤‘ í•˜ë‚˜ë¡œì„œ íšŒì‚¬ ìƒì¥ì— ê¸°ì—¬\\n\\nPython Â· R Â· pandas Â· NumPy Â· scikit-learn Â· Bioinformatics tools (survival, survminer, lifelines, GSEA, etc.) Â· Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<í”„ë¡œì íŠ¸2 : í•­ì•”ì œ í”Œë«í¼ ê³ ë„í™” í”„ë¡œì íŠ¸>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : ì•”ì¢… ë³„, ìœ ì „ì ì˜ˆí›„ ì˜ˆì¸¡ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©'),\n",
       " Document(metadata={'chunk_id': '0', 'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx'}, page_content='ê²½ë ¥ê¸°ìˆ ì„œ\\n\\n[ê°œì¸ ì •ë³´]\\n\\nì´ë©”ì¼: fourleaves8@gmail.com\\n\\nì—°ë½ì²˜: 010-4788-7980\\n\\n\\n\\n[ì „ë¬¸ ë¶„ì•¼]\\n\\nâ€¢ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤       \\t\\t â€¢ AI ì—”ì§€ë‹ˆì–´ë§\\t\\n\\nâ€¢ ë°ì´í„° ë¶„ì„           \\t\\t â€¢ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\\n\\nâ€¢ ìƒë¬¼ë¶„ì ë° í™”í•™ê³µí•™ ì—°êµ¬\\n\\n\\n\\n[ìš”ì•½]\\n\\nì €ëŠ” ìƒëª…Â·ì˜í•™ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„ í”Œë«í¼ì„ êµ¬ì¶•í•œ ê²½í—˜ ë° ë³µì¡í•œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì„í•´ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•˜ëŠ” ì—­ëŸ‰ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. Python ê¸°ë°˜ì˜ ë°ì´í„° ì „ì²˜ë¦¬, ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”, ë¶„ë¥˜ ë° ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œì„ í†µí•´ í•­ì•”ì œ ì‹ ê·œ ì ì‘ì¦ íƒìƒ‰ í”Œë«í¼ì„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•œ ë°” ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë°ì´í„° ìˆ˜ì§‘Â·ì •ê·œí™”Â·ì‹œê°í™” ì „ ê³¼ì •ì„ ì£¼ë„í•˜ë©°, ìŠ¤íƒ€íŠ¸ì—…ì˜ ì½”ìŠ¤ë‹¥ ìƒì¥ ë° ì‹¤ì œ ì œì•½ì‚¬ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•œ ì‹¤ë¬´ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤. \\n\\n\\n\\n[ë³´ìœ  ì—­ëŸ‰ ë° ê¸°ìˆ ]\\n\\ní”„ë¡œê·¸ë˜ë° ì–¸ì–´\\n\\nPython, R, SQL, Java\\n\\në„êµ¬ ë° í”„ë ˆì„ì›Œí¬'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '5'}, page_content='<í”„ë¡œì íŠ¸3 : ì—‘ì²´ìƒê²€ì„ í†µí•œ ì•” ì¡°ê¸° ì§„ë‹¨ ëª¨ë¸ ê°œë°œ>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : \\n\\ncfDNA, ctDNA ë°ì´í„° ìˆ˜ì§‘, ê´€ë¦¬, ë¶„ì„ \\n\\në©”íƒ€ë°ì´í„° ê´€ë¦¬ \\n\\nì•” ì§„ë‹¨ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2025.05â€“2025.11 (6ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : í˜ˆì•¡ cfDNA, ctDNA ë°ì´í„° ìˆ˜ì§‘ ë° í™œìš©, ì•” ì—¬ë¶€ ì˜ˆì¸¡ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ\\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 20%) : \\n\\nëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ (3000ìƒ˜í”Œ ì´ìƒ)\\n\\nì•” ì§„ë‹¨ CNNëª¨ë¸ ê°œë°œ (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)'),\n",
       " Document(metadata={'source': 'ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx', 'chunk_id': '4'}, page_content='<í”„ë¡œì íŠ¸2 : í•­ì•”ì œ í”Œë«í¼ ê³ ë„í™” í”„ë¡œì íŠ¸>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  : ì•”ì¢… ë³„, ìœ ì „ì ì˜ˆí›„ ì˜ˆì¸¡ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ê³ ë„í™”\\n\\n2) í”„ë¡œì íŠ¸ ìƒì„¸ ë‚´ìš©\\n\\ní”„ë¡œì íŠ¸ ê¸°ê°„ : 2024.01â€“2024.06 (6ê°œì›”)\\n\\nëª©í‘œ ë° ì—­í•  : 23ê°œ ì•”ì¢…ì— ëŒ€í•œ ìœ ì „ì ë³„ ì˜ˆí›„ ì ìˆ˜ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ì†ë„ 2ë°° (100%) ì´ìƒ ê°œì„ \\n\\nì„±ê³¼ (ê°œì¸ ê¸°ì—¬ë„: 100%) : \\n\\nì½”ì–´ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ ì „ë©´ ìˆ˜ì •\\n\\nì•Œê³ ë¦¬ì¦˜ ìŠ¤ì½”ì–´ë§ ì†ë„ 1100% í–¥ìƒ\\n\\nì•Œê³ ë¦¬ì¦˜ ê°œì„  í›„ ì†Œìš”ì‹œê°„: ìµœëŒ€ 1ì£¼ì¼ (ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜: ìµœì†Œ 3ê°œì›”)\\n\\nPython Â· pandas Â· NumPy Â· scikit-learn Â· Bioinformatics tools (lifelines, GSEA, etc.) Â· Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<í”„ë¡œì íŠ¸3 : ì—‘ì²´ìƒê²€ì„ í†µí•œ ì•” ì¡°ê¸° ì§„ë‹¨ ëª¨ë¸ ê°œë°œ>\\n\\n1) ë‹´ë‹¹ ì—…ë¬´ ë° ì—­í•  :')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('ë°ì´í„° ë¶„ì„')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfacb-ba53-469c-8142-84ce57500719",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. ì§ˆì˜ í•¨ìˆ˜: ê²€ìƒ‰ â†’ LLMì— ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ â†’ ì‘ë‹µ ë°›ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fabffce-fb3d-4a81-ab22-bce4fc42dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_from_docs(docs):\n",
    "    \"\"\"\n",
    "    docs: list of langchain Documents (or objects with page_content and metadata)\n",
    "    returns joined context string with small citations for traceability\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        mid = d.metadata if hasattr(d, \"metadata\") else {}\n",
    "        chunk_id = mid.get(\"chunk_id\", \"unknown\")\n",
    "        source = mid.get(\"source\", \"\")\n",
    "        parts.append(f\"[chunk_id: {chunk_id} | source: {source}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n",
    "\n",
    "def ask_question(question, chat_history=None, max_tokens=1000, temperature=0.0):\n",
    "    \"\"\"\n",
    "    - ê²€ìƒ‰ê¸°ë¡œ ë¬¸ì„œ ì¶”ì¶œ\n",
    "    - ì¶”ì¶œ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ OpenAI ChatCompletions í˜¸ì¶œ (gpt-4o-mini)\n",
    "    - chat_history: list of {\"role\": \"...\", \"content\": \"...\"} to preserve conversation (optional)\n",
    "    \"\"\"\n",
    "    # 1) ê²€ìƒ‰\n",
    "    relevant_docs = retriever.get_relevant_documents(question)  # returns Documents\n",
    "    context_text = build_context_from_docs(relevant_docs)\n",
    "\n",
    "    # 2) build messages\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "    # include chat history to keep multi-turn context if provided\n",
    "    if chat_history:\n",
    "        messages.extend(chat_history)\n",
    "    # supply context as part of user message (clear delimiting)\n",
    "    user_msg = (\n",
    "        \"Use only the CONTEXT below to answer the QUESTION.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context_text}\\n\\n\"\n",
    "        f\"QUESTION: {question}\\n\\n\"\n",
    "        \"If the context doesn't contain an answer, say you don't have the info and suggest next steps.\\n\"\n",
    "        \"Please include which chunk_id(s) you used to form the answer.\\n\"\n",
    "    )\n",
    "    messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "\n",
    "    # 3) call OpenAI Chat Completions (gpt-4o-mini)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    # parse response\n",
    "    content = resp.choices[0].message[\"content\"]\n",
    "    # attach used sources for traceability:\n",
    "    used_chunk_ids = [d.metadata.get(\"chunk_id\") for d in relevant_docs]\n",
    "    return {\n",
    "        \"answer\": content,\n",
    "        \"used_chunks\": used_chunk_ids,\n",
    "        \"relevant_docs\": relevant_docs,\n",
    "        \"raw_api_response\": resp\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ba1ac-cef1-4328-ad85-3f46884d3a12",
   "metadata": {},
   "source": [
    "## êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b056d123-fd7a-491f-adab-72b03f5d1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9246e3ee-31be-4887-aab5-4fbceba3cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 15:42:06.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# 1. API KEY\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "st.title(\"ğŸ’¬ ìê¸°ì†Œê°œì„œ ì‘ì„± ë„ìš°ë¯¸\")\n",
    "\n",
    "# 2. ê²½ë ¥ê¸°ìˆ ì„œ ì—…ë¡œë“œ\n",
    "uploaded_file = st.file_uploader(\"ê²½ë ¥ê¸°ìˆ ì„œ ì—…ë¡œë“œ (.pdf/.docx)\", type=['pdf','docx'])\n",
    "if uploaded_file:\n",
    "    if uploaded_file.name.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(uploaded_file)\n",
    "    else:\n",
    "        loader = Docx2txtLoader(uploaded_file)\n",
    "    docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99846a3c-4fb0-4476-8755-2f202918df10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
