{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af3cb2d-a2a3-4678-adb0-aed0935a73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from docx2txt import docx2txt  # optional, but you used Docx2txtLoader previously\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad355284-e0cc-4b90-a93e-90d59d654c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY 불러와 환경변수로 저장\n",
    "load_dotenv()  # 현재 경로의 .env 로드\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "if not os.environ['OPENAI_API_KEY']:\n",
    "    raise ValueError('OPENAI_API_KEY not found in environment. set it in .env or env vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99ffd3e-9b55-445d-af03-5244b965f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client (직접 chat.completions 호출용)\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb14d70-0699-4556-bd0a-e6a73e33d360",
   "metadata": {},
   "source": [
    "## 1. 문서 불러오기 & 텍스트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6885f599-b6b6-411d-88df-2b3709027597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 로드\n",
    "docx_path = \"../data/langchainThon/cv/경력기술서_천승우.docx\"\n",
    "full_text = docx2txt.process(docx_path)  # 전체 텍스트 하나로 읽힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79bd8082-bb1c-4ef0-ac4c-2ac21d9d7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 나누기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n'],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "chunks = text_splitter.split_text(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00c6df7-a869-4759-b274-ecfbc2fec1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 리스트에 metadata 추가\n",
    "documents = []\n",
    "for i, c in enumerate(chunks):\n",
    "    metadata = {\n",
    "        \"source\": \"경력기술서_천승우.docx\",\n",
    "        \"chunk_id\": str(i),\n",
    "        # 필요하면 더 많은 메타 추가 (예: section headings, page num)\n",
    "    }\n",
    "    documents.append(Document(page_content=c, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff30dc7f-93bb-4f0f-8245-8e6de760ae48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '0'}, page_content='경력기술서\\n\\n[개인 정보]\\n\\n이메일: fourleaves8@gmail.com\\n\\n연락처: 010-4788-7980\\n\\n\\n\\n[전문 분야]\\n\\n• 데이터 사이언스       \\t\\t • AI 엔지니어링\\t\\n\\n• 데이터 분석           \\t\\t • 프롬프트 엔지니어링\\n\\n• 생물분자 및 화학공학 연구\\n\\n\\n\\n[요약]\\n\\n저는 생명·의학 데이터를 처리하고 분석 플랫폼을 구축한 경험 및 복잡한 데이터를 효율적으로 분석해 의사결정을 지원하는 역량을 갖추고 있습니다. Python 기반의 데이터 전처리, 알고리즘 고도화, 분류 및 예측 모델 개발을 통해 항암제 신규 적응증 탐색 플랫폼을 성공적으로 구현한 바 있습니다. 또한 데이터 수집·정규화·시각화 전 과정을 주도하며, 스타트업의 코스닥 상장 및 실제 제약사 프로젝트에 기여한 실무 경험을 쌓았습니다. \\n\\n\\n\\n[보유 역량 및 기술]\\n\\n프로그래밍 언어\\n\\nPython, R, SQL, Java\\n\\n도구 및 프레임워크'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '1'}, page_content='[보유 역량 및 기술]\\n\\n프로그래밍 언어\\n\\nPython, R, SQL, Java\\n\\n도구 및 프레임워크\\n\\npandas, NumPy, Matplotlib, seaborn, Plotly, scikit-learn, PyTorch, TensorFlow, RAG, LangChain, MySQL, Oracle\\n\\n운영체제\\n\\nLinux(Ubuntu), Windows, macOS\\n\\nPalantir Foundry\\n\\nPipeline Builder, Contour, Ontology(Action), Workshop, AIP, Dataset\\n\\n기타\\n\\nVim / Vi, Git / GitHub, Bioinformatics Tools (Gene Set Enrichment Analysis, Bismark, Metilene, lifelines, survival, survminer, lifelines)\\n\\n\\n\\n[주요 경력 및 프로젝트]'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '2'}, page_content='[주요 경력 및 프로젝트]\\n\\n(주)온코크로스 · AI 연구소 · 주임연구원–전임연구원 · 2021.01–2024.12 (4년간 근무)\\n\\n\\n\\n<프로젝트1 : 항암제 신규 적응증 탐색 플랫폼 개발 프로젝트>\\n\\n1) 담당 업무 및 역할: 플랫폼 전체 기능 Python으로 재 구현, 내재화 및 오퍼레이션\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2021.01–2024.01 (36개월)\\n\\n목표 및 역할 : 플랫폼 개발/운영 · 전사체 데이터 및 의료 메타데이터 관리/분석\\n\\n성과 (개인 기여도: 70%) :\\n\\n플랫폼 전체 기능 Python 구현 및 내재화 완료\\n\\n플랫폼 오퍼레이션 전반에 대한 유지, 보수, 관리 및 분석 프로젝트를 수행함\\n\\n공공 데이터베이스로부터 23개 암종에 걸쳐 약 24,000개 샘플 데이터를 수집하여 대규모 분석 기반을 구축함\\n\\n수집한 샘플 전사체 데이터 정규화 및 정량적 유전자 발현량으로 변환하여 분석 가능한 데이터셋을 구축함\\n\\n플랫폼 대표 성공 사례'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '3'}, page_content='수집한 샘플 전사체 데이터 정규화 및 정량적 유전자 발현량으로 변환하여 분석 가능한 데이터셋을 구축함\\n\\n플랫폼 대표 성공 사례\\n\\n중국 ㅇㅇㅇ사 개발 신규 항암제의 주 적응증 예측 성공 및 잠재 적응증 후보 추가 제안\\n\\n국내 유명 제약사와 협업 – 후보물질 개발 단계 참여, 개발 물질에 대한 적응증 후보 도출, 최종 약물 타깃으로 선정되어 개발 지속\\n\\n상장 기술평가 항목 3가지 플랫폼 중 하나로서 회사 상장에 기여\\n\\nPython · R · pandas · NumPy · scikit-learn · Bioinformatics tools (survival, survminer, lifelines, GSEA, etc.) · Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<프로젝트2 : 항암제 플랫폼 고도화 프로젝트>\\n\\n1) 담당 업무 및 역할 : 암종 별, 유전자 예후 예측 스코어링 알고리즘 고도화\\n\\n2) 프로젝트 상세 내용'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '4'}, page_content='<프로젝트2 : 항암제 플랫폼 고도화 프로젝트>\\n\\n1) 담당 업무 및 역할 : 암종 별, 유전자 예후 예측 스코어링 알고리즘 고도화\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2024.01–2024.06 (6개월)\\n\\n목표 및 역할 : 23개 암종에 대한 유전자 별 예후 점수 스코어링 알고리즘 속도 2배 (100%) 이상 개선\\n\\n성과 (개인 기여도: 100%) : \\n\\n코어 스코어링 알고리즘 전면 수정\\n\\n알고리즘 스코어링 속도 1100% 향상\\n\\n알고리즘 개선 후 소요시간: 최대 1주일 (기존 알고리즘: 최소 3개월)\\n\\nPython · pandas · NumPy · scikit-learn · Bioinformatics tools (lifelines, GSEA, etc.) · Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<프로젝트3 : 엑체생검을 통한 암 조기 진단 모델 개발>\\n\\n1) 담당 업무 및 역할 :'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '5'}, page_content='<프로젝트3 : 엑체생검을 통한 암 조기 진단 모델 개발>\\n\\n1) 담당 업무 및 역할 : \\n\\ncfDNA, ctDNA 데이터 수집, 관리, 분석 \\n\\n메타데이터 관리 \\n\\n암 진단 딥러닝 모델 개발\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2025.05–2025.11 (6개월)\\n\\n목표 및 역할 : 혈액 cfDNA, ctDNA 데이터 수집 및 활용, 암 여부 예측 딥러닝 모델 개발\\n\\n성과 (개인 기여도: 20%) : \\n\\n모델 훈련을 위한 데이터 수집 (3000샘플 이상)\\n\\n암 진단 CNN모델 개발 (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '6'}, page_content='모델 훈련을 위한 데이터 수집 (3000샘플 이상)\\n\\n암 진단 CNN모델 개발 (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)\\n\\nPython · pandas · NumPy · PyTorch, TensorFlow · scikit-learn · Bioinformatics tools (GSEA, Bismark, Metilene) · Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<프로젝트4 : 신규 COVID-19 치료 후보 약물 탐색 및 연구 결과 논문 게재>\\n\\n1) 담당 업무 및 역할 : Dry-lab 연구, 내용 정리 및 논문 작성\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2024.01–present (21개월)\\n\\n목표 및 역할 : 공동 1저자(주 저자), 논문 Submission (2024.05.09)\\n\\n성과 (개인 기여도: 40%) :'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '7'}, page_content='목표 및 역할 : 공동 1저자(주 저자), 논문 Submission (2024.05.09)\\n\\n성과 (개인 기여도: 40%) : \\n\\n사내 플랫폼 활용 COVID-19 치료 유력 후보물질 발굴 성공\\n\\n연구 결과 Scientific reports 저널에 제출\\n\\n2025년 9월 현재까지 revision 진행중 (in press)\\n\\nPython · pandas · NumPy · scikit-learn · GSEA · Visualization packages (Matplotlib, seaborn)\\n\\n\\n\\n[자격증]\\n\\nOPIc(영어) · AL (Advanced Low) · 2024.09.20\\n\\n데이터 분석 준전문가 (ADsP) · 2025.09.05\\n\\n\\n\\n[교육 수료]\\n\\nGoogle Advanced Data Analytics – Foundations of Data Science\\n\\nGoogle Advanced Data Analytics – Get Started with Python'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '8'}, page_content='Google Advanced Data Analytics – Get Started with Python\\n\\nGoogle Advanced Data Analytics – Go Beyond the Numbers: Translate Data into Insights\\n\\nGoogle Advanced Data Analytics – The Power of Statistics\\n\\nGoogle Advanced Data Analytics – Regression Analysis: Simplify Complex Data Relationships\\n\\nGoogle Advanced Data Analytics – The Nuts and Bolts of Machine Learning\\n\\nPalantir Foundry – Speedrun: Your First End-to-End Workflow\\n\\nPalantir Foundry – Speedrun: Your First AIP workflow'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '9'}, page_content='Palantir Foundry – Speedrun: Your First AIP workflow\\n\\nPalantir Foundry – Deep Dive: Building Your First Pipeline\\n\\nPalantir Foundry – Deep Dive: Creating Your First Ontology\\n\\nPalantir Foundry – Deep Dive: Transforming Your Data with Code Repositories\\n\\nPalantir Foundry – Deep Dive: Building Your First Application\\n\\nPalantir Foundry – Deep Dive: Data Analysis in Contour\\n\\n모두의 연구소 – 데이터 사이언티스트 과정 Bootcamp (2025.06~현재 진행중)\\n\\n\\n\\n[학력]\\n\\n학위\\n\\n전공\\n\\n학교\\n\\n기간\\n\\n박사 (수료)\\n\\n생명화학공학\\n\\n한국과학기술원 (KAIST, 대전)'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '10'}, page_content='[학력]\\n\\n학위\\n\\n전공\\n\\n학교\\n\\n기간\\n\\n박사 (수료)\\n\\n생명화학공학\\n\\n한국과학기술원 (KAIST, 대전)\\n\\n2015.08 – 2020.09\\n\\n석사 (졸업)\\n\\n생명화학공학\\n\\n한국과학기술원 (KAIST, 대전)\\n\\n2015.08 – 2020.09\\n\\n학사 (졸업)\\n\\n생명과학\\n\\nVirginia Tech (미국)\\n\\n2011.08\\n\\n\\n\\n[기타]\\n\\nGithub Personal Project Repository\\n\\n(https://github.com/milkpotato1000/modulabs_projects)\\n\\nData Science & AI학습 블로그 \\n\\n(https://velog.io/@milkpotato1000/posts)\\n\\n\\n\\n\\n\\n     2')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e03f9c-6738-40bf-8394-4d9896379b8c",
   "metadata": {},
   "source": [
    "## 2. 임베딩 생성 및 벡터 DB 생성 (Chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8216d644-955c-4b23-a62b-4ae1a45267d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Chroma 벡터스토어 생성 (persist_directory 지정하면 재사용 가능)\n",
    "persist_dir = './chroma_resume_db'\n",
    "if not os.path.exists(persist_dir):\n",
    "    os.makedirs(persist_dir, exist_ok=True)\n",
    "\n",
    "# Chroma.from_documents 을 쓰면 내부에서 임베딩 생성 후 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name='resume_seungwoo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892ff3d-0588-4085-ac2d-1d37669a4b43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Retriever 구성 (검색 옵션: simple similarity or MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06a4aa80-ccdb-43da-af34-d25f347c16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as_retriever로 검색 방식 바꿀 수 있음\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',  # mmr로 다양성 있는 결과 (다른 옵션: \"similarity\")\n",
    "    search_kwargs={'k': 4, 'fetch_k': 10, 'lambda_mult': 0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "446837a5-52a6-413b-bbe7-a6e87c874635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'chunk_id': '3', 'source': '경력기술서_천승우.docx'}, page_content='수집한 샘플 전사체 데이터 정규화 및 정량적 유전자 발현량으로 변환하여 분석 가능한 데이터셋을 구축함\\n\\n플랫폼 대표 성공 사례\\n\\n중국 ㅇㅇㅇ사 개발 신규 항암제의 주 적응증 예측 성공 및 잠재 적응증 후보 추가 제안\\n\\n국내 유명 제약사와 협업 – 후보물질 개발 단계 참여, 개발 물질에 대한 적응증 후보 도출, 최종 약물 타깃으로 선정되어 개발 지속\\n\\n상장 기술평가 항목 3가지 플랫폼 중 하나로서 회사 상장에 기여\\n\\nPython · R · pandas · NumPy · scikit-learn · Bioinformatics tools (survival, survminer, lifelines, GSEA, etc.) · Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<프로젝트2 : 항암제 플랫폼 고도화 프로젝트>\\n\\n1) 담당 업무 및 역할 : 암종 별, 유전자 예후 예측 스코어링 알고리즘 고도화\\n\\n2) 프로젝트 상세 내용'),\n",
       " Document(metadata={'chunk_id': '0', 'source': '경력기술서_천승우.docx'}, page_content='경력기술서\\n\\n[개인 정보]\\n\\n이메일: fourleaves8@gmail.com\\n\\n연락처: 010-4788-7980\\n\\n\\n\\n[전문 분야]\\n\\n• 데이터 사이언스       \\t\\t • AI 엔지니어링\\t\\n\\n• 데이터 분석           \\t\\t • 프롬프트 엔지니어링\\n\\n• 생물분자 및 화학공학 연구\\n\\n\\n\\n[요약]\\n\\n저는 생명·의학 데이터를 처리하고 분석 플랫폼을 구축한 경험 및 복잡한 데이터를 효율적으로 분석해 의사결정을 지원하는 역량을 갖추고 있습니다. Python 기반의 데이터 전처리, 알고리즘 고도화, 분류 및 예측 모델 개발을 통해 항암제 신규 적응증 탐색 플랫폼을 성공적으로 구현한 바 있습니다. 또한 데이터 수집·정규화·시각화 전 과정을 주도하며, 스타트업의 코스닥 상장 및 실제 제약사 프로젝트에 기여한 실무 경험을 쌓았습니다. \\n\\n\\n\\n[보유 역량 및 기술]\\n\\n프로그래밍 언어\\n\\nPython, R, SQL, Java\\n\\n도구 및 프레임워크'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '5'}, page_content='<프로젝트3 : 엑체생검을 통한 암 조기 진단 모델 개발>\\n\\n1) 담당 업무 및 역할 : \\n\\ncfDNA, ctDNA 데이터 수집, 관리, 분석 \\n\\n메타데이터 관리 \\n\\n암 진단 딥러닝 모델 개발\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2025.05–2025.11 (6개월)\\n\\n목표 및 역할 : 혈액 cfDNA, ctDNA 데이터 수집 및 활용, 암 여부 예측 딥러닝 모델 개발\\n\\n성과 (개인 기여도: 20%) : \\n\\n모델 훈련을 위한 데이터 수집 (3000샘플 이상)\\n\\n암 진단 CNN모델 개발 (Recall: 0.69, Precision: 0.64, ROC-AUC: 0.71)'),\n",
       " Document(metadata={'source': '경력기술서_천승우.docx', 'chunk_id': '4'}, page_content='<프로젝트2 : 항암제 플랫폼 고도화 프로젝트>\\n\\n1) 담당 업무 및 역할 : 암종 별, 유전자 예후 예측 스코어링 알고리즘 고도화\\n\\n2) 프로젝트 상세 내용\\n\\n프로젝트 기간 : 2024.01–2024.06 (6개월)\\n\\n목표 및 역할 : 23개 암종에 대한 유전자 별 예후 점수 스코어링 알고리즘 속도 2배 (100%) 이상 개선\\n\\n성과 (개인 기여도: 100%) : \\n\\n코어 스코어링 알고리즘 전면 수정\\n\\n알고리즘 스코어링 속도 1100% 향상\\n\\n알고리즘 개선 후 소요시간: 최대 1주일 (기존 알고리즘: 최소 3개월)\\n\\nPython · pandas · NumPy · scikit-learn · Bioinformatics tools (lifelines, GSEA, etc.) · Visualization packages (Matplotlib, seaborn, Plotly, etc.)\\n\\n\\n\\n<프로젝트3 : 엑체생검을 통한 암 조기 진단 모델 개발>\\n\\n1) 담당 업무 및 역할 :')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('데이터 분석')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfacb-ba53-469c-8142-84ce57500719",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. 질의 함수: 검색 → LLM에 컨텍스트 전달 → 응답 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fabffce-fb3d-4a81-ab22-bce4fc42dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_from_docs(docs):\n",
    "    \"\"\"\n",
    "    docs: list of langchain Documents (or objects with page_content and metadata)\n",
    "    returns joined context string with small citations for traceability\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for d in docs:\n",
    "        mid = d.metadata if hasattr(d, \"metadata\") else {}\n",
    "        chunk_id = mid.get(\"chunk_id\", \"unknown\")\n",
    "        source = mid.get(\"source\", \"\")\n",
    "        parts.append(f\"[chunk_id: {chunk_id} | source: {source}]\\n{d.page_content}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n",
    "\n",
    "def ask_question(question, chat_history=None, max_tokens=1000, temperature=0.0):\n",
    "    \"\"\"\n",
    "    - 검색기로 문서 추출\n",
    "    - 추출 문서들을 컨텍스트로 묶어 OpenAI ChatCompletions 호출 (gpt-4o-mini)\n",
    "    - chat_history: list of {\"role\": \"...\", \"content\": \"...\"} to preserve conversation (optional)\n",
    "    \"\"\"\n",
    "    # 1) 검색\n",
    "    relevant_docs = retriever.get_relevant_documents(question)  # returns Documents\n",
    "    context_text = build_context_from_docs(relevant_docs)\n",
    "\n",
    "    # 2) build messages\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "    # include chat history to keep multi-turn context if provided\n",
    "    if chat_history:\n",
    "        messages.extend(chat_history)\n",
    "    # supply context as part of user message (clear delimiting)\n",
    "    user_msg = (\n",
    "        \"Use only the CONTEXT below to answer the QUESTION.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context_text}\\n\\n\"\n",
    "        f\"QUESTION: {question}\\n\\n\"\n",
    "        \"If the context doesn't contain an answer, say you don't have the info and suggest next steps.\\n\"\n",
    "        \"Please include which chunk_id(s) you used to form the answer.\\n\"\n",
    "    )\n",
    "    messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "\n",
    "    # 3) call OpenAI Chat Completions (gpt-4o-mini)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    # parse response\n",
    "    content = resp.choices[0].message[\"content\"]\n",
    "    # attach used sources for traceability:\n",
    "    used_chunk_ids = [d.metadata.get(\"chunk_id\") for d in relevant_docs]\n",
    "    return {\n",
    "        \"answer\": content,\n",
    "        \"used_chunks\": used_chunk_ids,\n",
    "        \"relevant_docs\": relevant_docs,\n",
    "        \"raw_api_response\": resp\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ba1ac-cef1-4328-ad85-3f46884d3a12",
   "metadata": {},
   "source": [
    "## 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b056d123-fd7a-491f-adab-72b03f5d1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9246e3ee-31be-4887-aab5-4fbceba3cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 15:42:06.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-24 15:42:06.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# 1. API KEY\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "st.title(\"💬 자기소개서 작성 도우미\")\n",
    "\n",
    "# 2. 경력기술서 업로드\n",
    "uploaded_file = st.file_uploader(\"경력기술서 업로드 (.pdf/.docx)\", type=['pdf','docx'])\n",
    "if uploaded_file:\n",
    "    if uploaded_file.name.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(uploaded_file)\n",
    "    else:\n",
    "        loader = Docx2txtLoader(uploaded_file)\n",
    "    docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99846a3c-4fb0-4476-8755-2f202918df10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
