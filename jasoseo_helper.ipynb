{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b7a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tempfile\n",
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import MultiRetrievalQAChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9020ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì˜¤í”ˆAI API í‚¤ ì„¤ì •\n",
    "load_dotenv()  # í˜„ì¬ ê²½ë¡œì˜ .env ë¡œë“œ\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "if not os.environ['OPENAI_API_KEY']:\n",
    "    raise ValueError('OPENAI_API_KEY not found in environment. set it in .env or env vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f82f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/langchainThon/cv/ê²½ë ¥ê¸°ìˆ ì„œ_ì²œìŠ¹ìš°.docx'\n",
    "# íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ ëª¨ë“œë¡œ ì½ì–´ì„œ _fileì²˜ëŸ¼ í‰ë‚´ë‚´ê¸°\n",
    "class DummyFile:\n",
    "    def __init__(self, path):\n",
    "        self.name = path\n",
    "        with open(path, \"rb\") as f:\n",
    "            self._data = f.read()\n",
    "    def getvalue(self):\n",
    "        return self._data\n",
    "\n",
    "_file = DummyFile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87819ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV ë¶ˆëŸ¬ì˜¤ê¸° (PDF/Word)\n",
    "def load_cv(_file):\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n",
    "        tmp_file.write(_file.getvalue())\n",
    "        tmp_file_path = tmp_file.name\n",
    "        \n",
    "    #PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "    if _file.name.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(file_path=tmp_file_path)\n",
    "    \n",
    "    #Word íŒŒì¼ ì—…ë¡œë“œ\n",
    "    elif _file.name.endswith('.docx'):\n",
    "        loader = Docx2txtLoader(file_path=tmp_file_path)\n",
    "    \n",
    "    # íŒŒì¼ í˜•ì‹ì´ í‹€ë¦´ê²½ìš° ì—ëŸ¬ ë©”ì„¸ì§€ ì¶œë ¥\n",
    "    else:\n",
    "        raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” DOCXë§Œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    pages = loader.load()\n",
    "    return pages\n",
    "\n",
    "# JD ë¶ˆëŸ¬ì˜¤ê¸° (URL)\n",
    "def load_jd(_url: str):\n",
    "    import warnings\n",
    "    from urllib3.exceptions import InsecureRequestWarning\n",
    "    warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "    \n",
    "    loader = WebBaseLoader(_url)\n",
    "    loader.requests_kwargs = {'verify': False}  # SSL ê²€ì¦ ë¹„í™œì„±í™”\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bc3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(docs, source_label, chunk_size=4000, chunk_overlap=100):\n",
    "    '''\n",
    "    í˜ì´ì§€(Document list)ë“¤ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  metadataë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\n",
    "    - docs: Document list\n",
    "    - source_label: 'cv' ë˜ëŠ” 'jd' ë“± source í‘œì‹œ\n",
    "    - return: ì²­í¬ê°€ ë‚˜ë‰œ Document ë¦¬ìŠ¤íŠ¸\n",
    "    '''\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=['\\n\\n', '\\n', ' '],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    split_docs_with_meta = [\n",
    "        Document(page_content=d.page_content,\n",
    "                 metadata={'source': source_label, 'chunk_id': str(i)},)\n",
    "        for i, d in enumerate(split_docs)\n",
    "    ]\n",
    "\n",
    "    return split_docs_with_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459295c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_docs = chunk_documents(load_cv(_file), 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f9f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_docs = chunk_documents(load_jd('https://www.wanted.co.kr/wd/297589'), 'jd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2df810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë¼ì´ì–¸íŠ¸ ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "client_chroma = Client(Settings(is_persistent=False))\n",
    "embeddings  = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=cv_docs+jd_docs,\n",
    "    embedding=embeddings,\n",
    "    client=client_chroma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Retriever ì„¤ì •\n",
    "# -----------------------------\n",
    "# CV Retriever\n",
    "cv_retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 5, 'filter': {'source': 'cv'}}\n",
    ")\n",
    "# JD Retriever\n",
    "jd_retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 5, 'filter': {'source': 'jd'}}\n",
    ")\n",
    "# Default Retriever\n",
    "default_retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 6}\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# System prompt ìƒì„±\n",
    "# -----------------------------\n",
    "system_prompt = '''\n",
    "ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ë° ì±„ìš© ê´€ë ¨ ì§ˆì˜ì‘ë‹µì„ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.  \n",
    "ì•„ë˜ ì œê³µëœ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.  \n",
    "\n",
    "- ì‚¬ìš©ìì˜ **ê²½ë ¥, ê²½í—˜, ì´ë ¥ ê´€ë ¨ ì§ˆë¬¸**ì´ë¼ë©´ CV(ì´ë ¥ì„œ)ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì„¸ìš”.  \n",
    "- **ì§€ì›í•˜ëŠ” íšŒì‚¬, ì§ë¬´, ì±„ìš© ìš”ê±´** ê´€ë ¨ ì§ˆë¬¸ì´ë¼ë©´ JD(ê³µê³ ë¬¸)ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì„¸ìš”.  \n",
    "- ì§ˆë¬¸ì˜ ë§¥ë½ìƒ ë‘ ë¬¸ì„œê°€ ëª¨ë‘ ê´€ë ¨ë˜ì–´ ìˆë‹¤ë©´, **ê· í˜• ìˆê²Œ í†µí•©í•˜ì—¬ ë‹µë³€**í•˜ì„¸ìš”.  \n",
    "- ë¬¸ì„œì— ì§ì ‘ì ì¸ ì •ë³´ê°€ ì—†ì„ ê²½ìš°, ì¼ë°˜ì ì¸ HR/ì»¤ë¦¬ì–´ ìƒì‹ê³¼ ë…¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³´ì™„í•´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ìê¸°ì†Œê°œì„œ ì‘ì„± ë˜ëŠ” ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ìš”ì²­ì‹œ ê°ê° ì•„ë˜ì™€ ê°™ì€ ì§€ì¹¨ì„ ë”°ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "** ìê¸°ì†Œê°œì„œ ì‘ì„± ì§€ì¹¨**\n",
    "- ìì—°ìŠ¤ëŸ½ê³  ì–µì§€ìŠ¤ëŸ½ì§€ ì•Šì€ ë¬¸ì¥ìœ¼ë¡œ ê¼­ í•„ìš”í•œ ë¶€ë¶„ì—ë§Œ CV ë‚´ìš©ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "- ê²½í—˜ê³¼ ê´€ë ¨ëœ ì‚¬ë¡€ë¥¼ ë“¤ì–´ì•¼ í•  ê²½ìš° ë°˜ë“œì‹œ CVì— ê¸°ìˆ ëœ ë‚´ìš©ë§Œì„ ì‚¬ì‹¤ëŒ€ë¡œ ë§í•©ë‹ˆë‹¤.\n",
    "- ì‘ì„±ëœ ê²½í—˜ë“¤ì„ ì ì ˆí•˜ê²Œ JDì—ì„œ ìš”êµ¬í•˜ëŠ” ëŠ¥ë ¥ ë° ì·¨ì—… í›„ ì„±ê³¼ ê¸°ì—¬ê°€ ê°€ëŠ¥í•¨ì˜ ê·¼ê±°ë¡œì¨ í™œìš©í•©ë‹ˆë‹¤.\n",
    "- ìê¸°ì†Œê°œì„œ ì‘ì„±ì‹œ ê¸€ììˆ˜ ì œí•œì€ í•œê¸€ì„ ê¸°ì¤€ìœ¼ë¡œ ë„ì–´ì“°ê¸°ë¥¼ í¬í•¨í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "- ì§ˆë¬¸ì§€ì— ì§ˆë¬¸ì˜ í•­ëª© ë˜ëŠ” ë²ˆí˜¸ê°€ ìˆë”ë¼ë„, ë¬¸ì¥ í˜•íƒœë¡œ ë‹µì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "** ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì§€ì¹¨**\n",
    "- íšŒì‚¬ JDë¥¼ ì°¸ê³ í•˜ì—¬ ì§€ì›ìì˜ ëŠ¥ë ¥ì„ í‰ê°€í•  ìˆ˜ ìˆì„ë§Œí•œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- ì¼ë°˜ì ì¸ HR/ì»¤ë¦¬ì–´ ìƒì‹ê³¼ ë…¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„± í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì–¸ì–´ ìŠ¤íƒ€ì¼ ì§€ì¹¨**\n",
    "- ë‹µë³€ì€ ì–¸ì œë‚˜ **ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” ì–´íˆ¬**ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.  \n",
    "- ë¬¸ì¥ì€ ëª…ë£Œí•˜ê³  ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë˜, ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì— ë§ëŠ” ì ì ˆí•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- í•„ìš” ì‹œ ê°€ë²¼ìš´ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì¹œê·¼í•¨ì„ ë”í•  ìˆ˜ ìˆìœ¼ë‚˜, ê³¼ë„í•˜ê²Œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n",
    "    \n",
    "ë¬¸ì„œ ë‚´ìš©:\n",
    "{context}\n",
    "'''\n",
    "\n",
    "# -----------------------------\n",
    "# ChatPromptTemplate ìƒì„±\n",
    "# -----------------------------\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MultiRetrievalQAChain êµ¬ì„±\n",
    "# -----------------------------\n",
    "retriever_infos = [\n",
    "    {\n",
    "        'name': 'cv',\n",
    "        'description': 'userì˜ ê²½ë ¥(CV) ë° ì´ì „ íšŒì‚¬ ê´€ë ¨ ì§ˆë¬¸',\n",
    "        'retriever': cv_retriever,\n",
    "        'prompt': qa_prompt\n",
    "    },\n",
    "    {\n",
    "        'name': 'jd',\n",
    "        'description': 'ì§€ì›í•˜ëŠ” íšŒì‚¬ ë° ì§ë¬´ê¸°ìˆ ì„œ(JD) ê´€ë ¨ ì§ˆë¬¸',\n",
    "        'retriever': jd_retriever,\n",
    "        'prompt': qa_prompt\n",
    "    },\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "\n",
    "rag_chain = MultiRetrievalQAChain.from_retrievers(\n",
    "    llm=llm,\n",
    "    retriever_infos=retriever_infos,\n",
    "    default_retriever=default_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058da902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  GPT-4o-mini ë‹µë³€:\n",
      "ê·€í•˜ê°€ ë‹¤ë…”ë˜ íšŒì‚¬ëŠ” (ì£¼)ì˜¨ì½”í¬ë¡œìŠ¤ì´ë©°, ê·¼ë¬´ ê¸°ê°„ì€ 2021ë…„ 1ì›”ë¶€í„° 2024ë…„ 12ì›”ê¹Œì§€ ì´ 4ë…„ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì´ì „ íšŒì‚¬ì—ì„œ ìˆ˜í–‰í•œ ì£¼ìš” í”„ë¡œì íŠ¸ ë„¤ ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í•­ì•”ì œ ì‹ ê·œ ì ì‘ì¦ íƒìƒ‰ í”Œë«í¼ ê°œë°œ í”„ë¡œì íŠ¸**: í”Œë«í¼ ì „ì²´ ê¸°ëŠ¥ì„ Pythonìœ¼ë¡œ ì¬êµ¬í˜„í•˜ê³ , 23ê°œ ì•”ì¢…ì— ê±¸ì³ ì•½ 24,000ê°œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ëŒ€ê·œëª¨ ë¶„ì„ ê¸°ë°˜ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì¤‘êµ­ ì œì•½ì‚¬ì˜ ì‹ ê·œ í•­ì•”ì œ ì ì‘ì¦ ì˜ˆì¸¡ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **í•­ì•”ì œ í”Œë«í¼ ê³ ë„í™” í”„ë¡œì íŠ¸**: ì•”ì¢… ë³„ ìœ ì „ì ì˜ˆí›„ ì˜ˆì¸¡ ìŠ¤ì½”ì–´ë§ ì•Œê³ ë¦¬ì¦˜ì„ ê³ ë„í™”í•˜ì—¬ ì•Œê³ ë¦¬ì¦˜ ìŠ¤ì½”ì–´ë§ ì†ë„ë¥¼ 1100% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ì˜ ì†Œìš” ì‹œê°„ì„ í¬ê²Œ ë‹¨ì¶•í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ì—‘ì²´ìƒê²€ì„ í†µí•œ ì•” ì¡°ê¸° ì§„ë‹¨ ëª¨ë¸ ê°œë°œ**: cfDNA ë° ctDNA ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ì—¬ ì•” ì—¬ë¶€ ì˜ˆì¸¡ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ Recall 0.69, Precision 0.64, ROC-AUC 0.71ì˜ ì„±ê³¼ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ì‹ ê·œ COVID-19 ì¹˜ë£Œ í›„ë³´ ì•½ë¬¼ íƒìƒ‰ ë° ì—°êµ¬ ê²°ê³¼ ë…¼ë¬¸ ê²Œì¬**: Dry-lab ì—°êµ¬ë¥¼ í†µí•´ COVID-19 ì¹˜ë£Œ ìœ ë ¥ í›„ë³´ë¬¼ì§ˆì„ ë°œêµ´í•˜ê³ , ì—°êµ¬ ê²°ê³¼ë¥¼ Scientific Reports ì €ë„ì— ì œì¶œí–ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ ë…¼ë¬¸ ìˆ˜ì • ì‘ì—…ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "query = 'ë‚´ê°€ ë‹¤ë…”ë˜ íšŒì‚¬ ì´ë¦„ê³¼ ê·¼ë¬´ ê¸°ê°„ì„ ë§ì¶°ë´. ì¶”ê°€ë¡œ ì´ì „ íšŒì‚¬ì—ì„œ í–ˆë˜ ì£¼ìš” í”„ë¡œì íŠ¸ ë„¤ê°€ì§€ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜.'\n",
    "response = rag_chain.invoke({'input': query})\n",
    "\n",
    "# LLM ë‹µë³€\n",
    "print('ğŸ§  GPT-4o-mini ë‹µë³€:')\n",
    "print(response['result'])  # MultiRetrievalQAChainëŠ” output_keys=['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2102485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  GPT-4o-mini ë‹µë³€:\n",
      "ë‹¹ì‹ ì´ ì§€ì›í•˜ë ¤ê³  í•˜ëŠ” íšŒì‚¬ëŠ” **ì„íŒ©í‹°ë¸ŒAI**ì…ë‹ˆë‹¤. ì´ íšŒì‚¬ëŠ” ìˆ˜ìš”ì˜ˆì¸¡ì— íŠ¹í™”ëœ AI ì†”ë£¨ì…˜ ì „ë¬¸ê¸°ì—…ìœ¼ë¡œ, ìì²´ ì†”ë£¨ì…˜ì¸ **Deepflow**ë¥¼ í†µí•´ ì œí’ˆ ìˆ˜ìš”ì˜ˆì¸¡, ì›ìì¬ ê°€ê²©ì˜ˆì¸¡, ì‹ ì œí’ˆ ì„±ê³¼ì˜ˆì¸¡ ë“±ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì„íŒ©í‹°ë¸ŒAIëŠ” ì œì¡° ë° ìœ í†µ ì‚°ì—…ì—ì„œ ê¸°ìˆ ë ¥ì„ ì¸ì •ë°›ìœ¼ë©° ê³ ê°ì‚¬ì˜ ì„±ê³¼ ì°½ì¶œì„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "query = 'ë‚´ê°€ ì§€ì›í•˜ë ¤ê³ í•˜ëŠ” íšŒì‚¬ëŠ”?'\n",
    "response = rag_chain.invoke({'input': query})\n",
    "\n",
    "# LLM ë‹µë³€\n",
    "print('ğŸ§  GPT-4o-mini ë‹µë³€:')\n",
    "print(response['result'])  # MultiRetrievalQAChainëŠ” output_keys=['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c09f7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  GPT-4o-mini ë‹µë³€:\n",
      "ì œê°€ ì§€ì›í•œ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ì§ë¬´ì—ì„œ ì„±ê³¼ë¥¼ ì°½ì¶œí•˜ê¸° ìœ„í•œ í•µì‹¬ì—­ëŸ‰ì€ **ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ëŠ¥ë ¥**ì…ë‹ˆë‹¤. ì´ ì—­ëŸ‰ì€ (1) ì§ë¬´ì „ë¬¸ì„± ì¸¡ë©´ì—ì„œ, ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ ë° ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë¡œì íŠ¸ ê²½í—˜ì„ í†µí•´ ê°•í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ì „ ì§ì¥ì—ì„œ ê³ ê°ì˜ íŒë§¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ 6ê°œì›” ê°„ì˜ íŒë§¤ëŸ‰ì„ 20% ì •í™•ë„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆì—ˆê³ , ì´ ê²°ê³¼ëŠ” ê³ ê°ì‚¬ì˜ ì¬ê³  ê´€ë¦¬ ìµœì í™”ì— ê¸°ì—¬í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½í—˜ì€ ì„íŒ©í‹°ë¸ŒAIì˜ Deepflow ì†”ë£¨ì…˜ì„ í†µí•´ ìˆ˜ìš”ì˜ˆì¸¡ ë° ì¬ê³ ê´€ë¦¬ ìµœì í™”ì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "(2) ì¡°ì§ê¸°ì—¬ ì¸¡ë©´ì—ì„œëŠ”, íŒ€ ë‚´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ ë° ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ì˜ í˜‘ì—…ì„ í†µí•´ ì˜ˆì¸¡ëª¨ë¸ì„ ê°œë°œí•˜ê³  ìµœì í™”í•˜ëŠ” ê³¼ì •ì—ì„œ ì œ ì—­ëŸ‰ì´ ë°œíœ˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„° ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³¼ì •ì—ì„œ íŒ€ì›ë“¤ê³¼ì˜ ì›í™œí•œ ì†Œí†µê³¼ í˜‘ë ¥ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í˜‘ì—… ê²½í—˜ì€ ì„íŒ©í‹°ë¸ŒAIì˜ ëª©í‘œì¸ ê³ ê°ì‚¬ì˜ ì„±ê³¼ ì°½ì¶œì„ ì§€ì›í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒì…ë‹ˆë‹¤. \n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, ì €ì˜ ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ëŠ¥ë ¥ì€ ì§ë¬´ì „ë¬¸ì„±ê³¼ ì¡°ì§ê¸°ì—¬ ë‘ ì¸¡ë©´ì—ì„œ ì„íŒ©í‹°ë¸ŒAIì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ë‹¬ì„±ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ìì‚°ì´ ë  ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "query = 'ì§€ì›í•˜ì‹  ì§ë¬´ì—ì„œ ì„±ê³¼ë¥¼ ì°½ì¶œí•˜ê¸° ìœ„í•œ ë³¸ì¸ë§Œì˜ í•µì‹¬ì—­ëŸ‰ì„ ì œì‹œí•˜ê³  ì´ê²ƒì´ (1)ì§ë¬´ì „ë¬¸ì„±, (2)ì¡°ì§ê¸°ì—¬ ì¸¡ë©´ì—ì„œ ì–´ë–»ê²Œ ë°œíœ˜ë  ìˆ˜ ìˆëŠ”ì§€ ì‚¬ë¡€ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì‹œì˜¤. (ìµœëŒ€ 800ì ì…ë ¥ê°€ëŠ¥)'\n",
    "response = rag_chain.invoke({'input': query})\n",
    "\n",
    "# LLM ë‹µë³€\n",
    "print('ğŸ§  GPT-4o-mini ë‹µë³€:')\n",
    "print(response['result'])  # MultiRetrievalQAChainëŠ” output_keys=['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec10af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  GPT-4o-mini ë‹µë³€:\n",
      "ë©´ì ‘ê´€ìœ¼ë¡œì„œ ì§€ì›ìì—ê²Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•œ ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ? í•´ë‹¹ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì™€ ëª¨ë¸ë§ ê¸°ë²•, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ê°€ ì–´ë–»ê²Œ ê³ ê°ì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí–ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "2. ë°ì´í„° ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³¼ì •ì—ì„œ ì§ë©´í–ˆë˜ ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì´ì—ˆìœ¼ë©°, ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ì˜€ëŠ”ì§€ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ì´ ê³¼ì •ì—ì„œ ì–´ë–¤ ë„êµ¬ë‚˜ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì…¨ëŠ”ì§€ë„ í¬í•¨í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "3. ìµœì‹  ë¨¸ì‹ ëŸ¬ë‹ ë° ë°ì´í„° ë¶„ì„ íŠ¸ë Œë“œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬, ì´ë¥¼ ì„íŒ©í‹°ë¸ŒAIì˜ ì˜ˆì¸¡ ëª¨ë¸ì— ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆì„ì§€ì— ëŒ€í•œ ê·€í•˜ì˜ ì˜ê²¬ì„ ë§ì”€í•´ ì£¼ì„¸ìš”. ì´ ê¸°ìˆ ì´ íšŒì‚¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì–´ë–¤ ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆì„ì§€ì— ëŒ€í•´ì„œë„ ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "query = 'ìŠ¤ìŠ¤ë¡œ ì§€ì›í•˜ë ¤ê³  í•˜ëŠ” íšŒì‚¬ì˜ ë©´ì ‘ê´€ì´ ë˜ì–´ ë©´ì ‘ì—ì„œ í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ì¶œë ¥í•´ì¤˜.'\n",
    "response = rag_chain.invoke({'input': query})\n",
    "\n",
    "# LLM ë‹µë³€\n",
    "print('ğŸ§  GPT-4o-mini ë‹µë³€:')\n",
    "print(response['result'])  # MultiRetrievalQAChainëŠ” output_keys=['result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
